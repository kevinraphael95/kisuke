# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ“Œ gpt_oss_client.py â€” Connexion cloud NVIDIA GPT-OSS (pour !!gpt et /rpgpt)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
from openai import OpenAI
import requests

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ”‘ ClÃ© NVIDIA (cloud)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("GPT_OSS_API_KEY")
BASE_URL = "https://integrate.api.nvidia.com/v1"

if not API_KEY:
    print("âŒ Aucune clÃ© GPT-OSS dÃ©tectÃ©e. Configure GPT_OSS_API_KEY dans ton environnement.")
else:
    print("âœ… ClÃ© NVIDIA GPT-OSS dÃ©tectÃ©e â€” utilisation du cloud.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âš™ï¸ Initialisation du client NVIDIA Cloud
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
client = OpenAI(base_url=BASE_URL, api_key=API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ’¬ RÃ©ponse simple (commande !!gpt)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_simple_response(prompt: str) -> str:
    """
    Envoie un simple prompt texte Ã  GPT-OSS NVIDIA (cloud) et renvoie la rÃ©ponse directe.
    UtilisÃ© pour la commande !!gpt.
    """
    try:
        # Consigne ajoutÃ©e automatiquement sans compter dans la limite utilisateur
        full_prompt = (
            prompt.strip()
            + "\n\nRÃ©ponds briÃ¨vement et clairement, en franÃ§ais, en 1 Ã  3 phrases maximum."
        )

        response = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Tu es un assistant conversationnel prÃ©cis, bienveillant et toujours francophone. "
                        "RÃ©ponds de maniÃ¨re naturelle et fluide."
                    ),
                },
                {"role": "user", "content": full_prompt},
            ],
            temperature=0.8,   # un peu plus libre pour Ã©viter les non-rÃ©ponses
            top_p=0.8,
            max_tokens=512,    # limite interne confortable (pas coupÃ©e brutalement)
        )

        msg = response.choices[0].message.content
        if not msg or not msg.strip():
            return "âš ï¸ Le modÃ¨le nâ€™a rien rÃ©pondu."
        msg = msg.strip()

        # Tronquer Ã  500 caractÃ¨res maximum
        if len(msg) > 500:
            msg = msg[:500].rstrip() + "â€¦"

        return msg

    except Exception as e:
        print(f"[Erreur GPT-OSS Simple] {type(e)} â€” {e}")
        return "âš ï¸ Le modÃ¨le est silencieux pour le moment..."

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ’¬ Continuation dâ€™histoire (utilisÃ©e par RPGPT)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_story_continuation(history: list[dict]) -> str:
    """
    Envoie l'historique du RPG Ã  GPT-OSS NVIDIA (cloud) et renvoie la suite de l'histoire.
    Chaque Ã©lÃ©ment de 'history' est une dict : {role: 'user'/'assistant'/'system', content: str}
    """
    try:
        response = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=history,
            temperature=0.95,
            top_p=0.7,
            max_tokens=1024
        )
        msg = response.choices[0].message.content
        if not msg:
            return "âš ï¸ Le narrateur se tait..."
        return msg.strip()
    except Exception as e:
        print(f"[Erreur GPT-OSS Histoire] {type(e)} â€” {e}")
        return "âš ï¸ Le narrateur se tait... (*erreur du modÃ¨le ou limite atteinte*)"

# --------------------------------------------------------------------- #
# Fonction pour rÃ©cupÃ©rer le quota restant
# --------------------------------------------------------------------- #
def remaining_tokens() -> int:
    """
    Retourne le nombre de tokens restants dans le quota mensuel NVIDIA GPT-OSS.
    Approximation : 100 000 tokens par mois (free-tier)
    """
    try:
        resp = requests.get(
            f"{BASE_URL}/usage",
            headers={"Authorization": f"Bearer {API_KEY}"},
            timeout=5
        )
        resp.raise_for_status()
        data = resp.json()
        used = data.get("token_used", 0)
        quota = data.get("token_quota", 100_000)
        return quota - used
    except Exception as e:
        print(f"[Erreur remaining_tokens] {e}")
        return 100_000
